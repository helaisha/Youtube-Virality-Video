{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Process(link):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    country = pd.read_csv(link)\n",
    "\n",
    "    country['trending_date'] = country.trending_date.apply(lambda date : '20' + str(date))\n",
    "    country['trending_date'] = country.trending_date.apply(lambda date : str(date).replace('.', '/'))\n",
    "    # Converting Trending date and publish time to datetime format\n",
    "    country.trending_date = pd.to_datetime(country['trending_date'], format = '%Y/%d/%m')\n",
    "    country.publish_time = pd.to_datetime(country['publish_time']).dt.tz_localize(None)   # to remove timestamp from date\n",
    "\n",
    "    country['NoTags'] = [len(tag.split('|')) for tag in country['tags']]\n",
    "    country['NoWord'] = [len(title.split(' ')) for title in country['title']]\n",
    "    country['NoChar'] = [len(title.strip(' ')) for title in country['title']]\n",
    "    country['TMonths'] = country['trending_date'].dt.month.astype(object)\n",
    "    country['PMonths'] = country['publish_time'].dt.month.astype(object)\n",
    "    country['Timediff'] = (country.trending_date - country.publish_time).dt.days\n",
    "\n",
    "    # Deleting unnecessary variables\n",
    "    country.drop(['video_id', 'category_id', 'thumbnail_link', 'description', 'title', 'channel_title', 'tags'], axis = 1, inplace = True )\n",
    "    #country = country[country['views'] >= 5000000]\n",
    "    \n",
    "    # Categorical Encoding\n",
    "    import category_encoders as ce\n",
    "    encoder = ce.BinaryEncoder(cols=['category', 'TMonths', 'PMonths'])\n",
    "    country1 = encoder.fit_transform(country)\n",
    "\n",
    "    # Feature Selection\n",
    "    Xn = country1.drop(['views','trending_date', 'publish_time'], axis= 1)\n",
    "    Yn = country1['views']\n",
    "\n",
    "    from sklearn.feature_selection import SelectKBest, f_regression\n",
    "    feat = SelectKBest(score_func=f_regression, k='all')\n",
    "    Selectd_X = feat.fit(Xn, Yn)\n",
    "    #print(Selectd_X.scores_)\n",
    "    score = pd.DataFrame(Selectd_X.scores_)\n",
    "    feat = pd.DataFrame(Xn.columns)\n",
    "    FeatScores = pd.concat([feat, score], axis =1)\n",
    "    FeatScores.columns=['Features','Score']\n",
    "    print(FeatScores.nlargest(20,'Score'))\n",
    "\n",
    "    country2 = country1[FeatScores['Features'][FeatScores['Score'] > 0]]\n",
    "    country2['views'] = country1['views'] \n",
    "    country2.shape\n",
    "\n",
    "    #Removing Outliers\n",
    "    Q1 = country2.quantile(0.25)\n",
    "    Q3 = country2.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    country3 = country2[~((country2 < (Q1 - 1.5 * IQR)) |(country2 > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "\n",
    "    # Modeling\n",
    "    Xn = country3.drop('views', axis =1)\n",
    "    Yn = np.log(country3['views'])\n",
    "\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()\n",
    "    X = sc.fit_transform(Xn)\n",
    "    #Y = sc.fit_transform(Yn.values.reshape(-1, 1))\n",
    "    \n",
    "    # Train and test split\n",
    "    from sklearn.model_selection import train_test_split, cross_val_score\n",
    "    train_X, test_X, train_y, test_y = train_test_split(X, Yn, test_size = 0.2, random_state=101)\n",
    "    from sklearn.metrics import mean_squared_error as mse\n",
    "    \n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    rfr = RandomForestRegressor(n_estimators=200, max_depth=100, random_state=2)\n",
    "    model1 = rfr.fit(train_X, train_y)\n",
    "    ypred = rfr.predict(test_X)\n",
    "    rmse0 = mse(test_y, ypred)**(1/2)\n",
    "    rfrscore = cross_val_score(rfr, train_X, train_y, cv=5)\n",
    "\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    lr = LinearRegression()\n",
    "    model2 = lr.fit(train_X, train_y)\n",
    "    ypred = lr.predict(test_X)\n",
    "    rmse1 = mse(test_y, ypred)**(1/2)\n",
    "    lrscore = cross_val_score(lr, train_X, train_y, cv=5)\n",
    "\n",
    "    from sklearn.svm import SVR\n",
    "    svr = SVR(kernel= 'rbf', degree = 3)\n",
    "    model3 = svr.fit(train_X, train_y)\n",
    "    ypred = svr.predict(test_X)\n",
    "    rmse2 = mse(test_y, ypred)**(1/2)\n",
    "    svscore = cross_val_score(svr, train_X, train_y, cv=5)\n",
    "\n",
    "    #from sklearn.model_selection import GridSearchCV\n",
    "    #from sklearn.neighbors import KNeighborsRegressor\n",
    "    #params = {'n_neighbors':list(range(1,21))}\n",
    "    #knn = KNeighborsRegressor()\n",
    "    #kn = GridSearchCV(knn, params, cv=5)\n",
    "    #kn.fit(train_X, train_y)\n",
    "    #y_pred = kn.predict(test_X)\n",
    "    #rmse3 = mse(test_y, ypred)**(1/2)\n",
    "    #knscore = cross_val_score(kn, X, Yn, cv=5)\n",
    "\n",
    "    print('Random forest: RMSE: ', round(rmse0, 3), 'Accuracy: %0.2f (+/- %0.2f)' %(rfrscore.mean() ,rfrscore.std() * 2))\n",
    "    print('linear Regression RMSE: ', round(rmse1, 3), 'Accuracy: %0.2f (+/- %0.2f)' %(lrscore.mean() ,lrscore.std() * 2))\n",
    "    print('Support Vector RMSE: ', round(rmse2, 3), 'Accuracy: %0.2f (+/- %0.2f)' %(svscore.mean() ,svscore.std() * 2))\n",
    "    #print('K-nearest RMSE: ', round(rmse3, 3), 'Accuracy: %0.2f (+/- %0.2f)' %(knscore.mean() ,knscore.std() * 2))\n",
    "    return"
   ]
  },
  
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Process('Data/Capstone/CA-ok.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Process('Data/Capstone/MX-ok.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Process('Data/Capstone/GB-ok.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Process('Data/Capstone/FR-ok.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Process('Data/Capstone/KR-ok.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Process('Data/Capstone/IN-ok.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Process('Data/Capstone/JP-ok.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Process('Data/Capstone/DE-ok.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Process('Data/Capstone/RU-ok.csv')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37564bitbaseconda52edd58351c6476fa35a1e475e0dad6a",
   "display_name": "Python 3.7.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
